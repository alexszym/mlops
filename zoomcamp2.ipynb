{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import mlflow\r\n",
        "\r\n",
        "mlflow.__version__"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "'1.20.2'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1653908717027
        }
      },
      "id": "9aee0568-15b7-46e8-84fc-81c0faeca76d"
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocess_data.py --raw_data_path ./raw_data --dest_path ./output"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "e64a663c-7f5b-4bf7-ac54-3b3f7aa632c1"
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\r\n",
        "\r\n",
        "mlflow.set_tracking_uri(URI)\r\n",
        "mlflow.set_experiment(\"taxi-poc\")"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1653908725659
        }
      },
      "id": "95916a35-f0d2-4423-bf43-54c8d22db6b4"
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\r\n",
        "import os\r\n",
        "import pickle\r\n",
        "\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "\r\n",
        "\r\n",
        "def load_pickle(filename: str):\r\n",
        "    with open(filename, \"rb\") as f_in:\r\n",
        "        return pickle.load(f_in)\r\n",
        "\r\n",
        "\r\n",
        "def run(data_path):\r\n",
        "\r\n",
        "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\r\n",
        "    X_valid, y_valid = load_pickle(os.path.join(data_path, \"valid.pkl\"))\r\n",
        "\r\n",
        "    rf = RandomForestRegressor(max_depth=10, random_state=0)\r\n",
        "    rf.fit(X_train, y_train)\r\n",
        "    y_pred = rf.predict(X_valid)\r\n",
        "\r\n",
        "    rmse = mean_squared_error(y_valid, y_pred, squared=False)\r\n",
        "    "
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1653908726075
        }
      },
      "id": "e7316904-9e60-43cf-943f-6ae2fea75442"
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.sklearn.autolog()\r\n",
        "\r\n",
        "with mlflow.start_run():\r\n",
        "\r\n",
        "    run(\"./output\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022/05/30 11:05:52 WARNING mlflow.sklearn: Failed to infer model signature: Expected one of (pandas.DataFrame, numpy array, dictionary of (name -> numpy.ndarray), pyspark.sql.DataFrame) but got '<class 'scipy.sparse.csr.csr_matrix'>'\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1653908759964
        }
      },
      "id": "1f218077-b86f-4f0b-a37b-40cf064354f7"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\r\n",
        "from hyperopt.pyll import scope\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "\r\n",
        "mlflow.sklearn.autolog(disable=True)\r\n",
        "\r\n",
        "def run2(data_path, num_trials):\r\n",
        "\r\n",
        "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\r\n",
        "    X_valid, y_valid = load_pickle(os.path.join(data_path, \"valid.pkl\"))\r\n",
        "\r\n",
        "    def objective(params):\r\n",
        "        with mlflow.start_run():\r\n",
        "            mlflow.set_tag(\"model\", \"random-forest-reg2\")\r\n",
        "            mlflow.log_params(params)\r\n",
        "            rf = RandomForestRegressor(**params)\r\n",
        "            rf.fit(X_train, y_train)\r\n",
        "            y_pred = rf.predict(X_valid)\r\n",
        "            rmse = mean_squared_error(y_valid, y_pred, squared=False)\r\n",
        "\r\n",
        "            mlflow.log_metric(\"rmse\", rmse)\r\n",
        "            return {'loss': rmse, 'status': STATUS_OK}\r\n",
        "\r\n",
        "    search_space = {\r\n",
        "        'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\r\n",
        "        'n_estimators': scope.int(hp.quniform('n_estimators', 10, 50, 1)),\r\n",
        "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\r\n",
        "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 4, 1)),\r\n",
        "        'random_state': 42\r\n",
        "    }\r\n",
        "\r\n",
        "    rstate = np.random.default_rng(42)  # for reproducible results\r\n",
        "    fmin(\r\n",
        "        fn=objective,\r\n",
        "        space=search_space,\r\n",
        "        algo=tpe.suggest,\r\n",
        "        max_evals=num_trials,\r\n",
        "        trials=Trials(),\r\n",
        "        rstate=rstate\r\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1653908760190
        }
      },
      "id": "dcb98a49-f264-4391-9f57-546c889f04cf"
    },
    {
      "cell_type": "code",
      "source": [
        "run2(\"./output\", 50)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1653909309774
        }
      },
      "id": "d69e5d7e-2c49-477d-a673-3dcaf1c46ce6"
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\r\n",
        "import os\r\n",
        "import pickle\r\n",
        "\r\n",
        "import mlflow\r\n",
        "from hyperopt import hp, space_eval\r\n",
        "from hyperopt.pyll import scope\r\n",
        "from mlflow.entities import ViewType\r\n",
        "from mlflow.tracking import MlflowClient\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "\r\n",
        "HPO_EXPERIMENT_NAME = \"taxi-poc\"\r\n",
        "EXPERIMENT_NAME = \"taxi-poc-best-models\"\r\n",
        "\r\n",
        "mlflow.set_experiment(EXPERIMENT_NAME)\r\n",
        "mlflow.sklearn.autolog()\r\n",
        "\r\n",
        "SPACE = {\r\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\r\n",
        "    'n_estimators': scope.int(hp.quniform('n_estimators', 10, 50, 1)),\r\n",
        "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\r\n",
        "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 4, 1)),\r\n",
        "    'random_state': 42\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "def train_and_log_model(data_path, params):\r\n",
        "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\r\n",
        "    X_valid, y_valid = load_pickle(os.path.join(data_path, \"valid.pkl\"))\r\n",
        "    X_test, y_test = load_pickle(os.path.join(data_path, \"test.pkl\"))\r\n",
        "\r\n",
        "    with mlflow.start_run():\r\n",
        "        params = space_eval(SPACE, params)\r\n",
        "        rf = RandomForestRegressor(**params)\r\n",
        "        rf.fit(X_train, y_train)\r\n",
        "\r\n",
        "        # evaluate model on the validation and test sets\r\n",
        "        valid_rmse = mean_squared_error(y_valid, rf.predict(X_valid), squared=False)\r\n",
        "        mlflow.log_metric(\"valid_rmse\", valid_rmse)\r\n",
        "        test_rmse = mean_squared_error(y_test, rf.predict(X_test), squared=False)\r\n",
        "        mlflow.log_metric(\"test_rmse\", test_rmse)\r\n",
        "\r\n",
        "\r\n",
        "def run3(data_path, log_top):\r\n",
        "\r\n",
        "    client = MlflowClient()\r\n",
        "\r\n",
        "    # retrieve the top_n model runs and log the models to MLflow\r\n",
        "    hpo_experiment = client.get_experiment_by_name(HPO_EXPERIMENT_NAME)\r\n",
        "    runs = client.search_runs(\r\n",
        "        experiment_ids=hpo_experiment.experiment_id,\r\n",
        "        run_view_type=ViewType.ACTIVE_ONLY,\r\n",
        "        max_results=log_top,\r\n",
        "        order_by=[\"metrics.rmse ASC\"]\r\n",
        "    )\r\n",
        "    for run in runs:\r\n",
        "        train_and_log_model(data_path=data_path, params=run.data.params)\r\n",
        "\r\n",
        "    experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\r\n",
        "    best_run = client.search_runs(\r\n",
        "        experiment_ids=experiment.experiment_id,\r\n",
        "        run_view_type=ViewType.ACTIVE_ONLY,\r\n",
        "        max_results=1,\r\n",
        "        order_by=[\"metrics.test_rmse ASC\"]\r\n",
        "    )[0]\r\n",
        "\r\n",
        "        # register the best model\r\n",
        "    model_uri = f\"runs:/{best_run.info.run_id}/model\"\r\n",
        "    mlflow.register_model(model_uri=model_uri, name='nyc-taxi-model' )\r\n",
        "\r\n",
        "run3(\"./output\", 5)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1653916568388
        }
      },
      "id": "8da1ebdd-b1b4-4e1b-8365-f96c12e0333b"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
